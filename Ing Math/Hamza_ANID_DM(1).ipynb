{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2a772c-5935-416f-8e63-603d64a2680c",
   "metadata": {},
   "source": [
    "<h1><center>Ingénierie Mathématique 3, Devoir Maison</center></h1>\n",
    "<h3><center>Nom & Prénom : ANID Hamza</center></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69ba21-9d27-4705-8fa6-9b762f7f6397",
   "metadata": {},
   "source": [
    "## Question 1 :Un premier modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f261af0b-edb7-4cf2-8fb3-1b723771b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X : (70000, 784)\n",
      "Dimensions de y : (70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données MNIST\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "print(\"Dimensions de X :\", X.shape)\n",
    "print(\"Dimensions de y :\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f53969a7-c5c5-4247-bb83-026a44cce87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)\n",
    "X = X / 255.0  \n",
    "# Extraire uniquement les images des classes 0 et 1 \n",
    "indices = np.where((y == 0) | (y == 1))\n",
    "X = X[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08f5ca0c-2fdc-4dbf-9e93-7b3bb4e6ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34106bea-006c-4de6-87b4-4c9e41f57ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(X, y, w):\n",
    "    m = X.shape[0]  \n",
    "    z = np.dot(X, w)  \n",
    "    y_pred = 1 / (1 + np.exp(-z))  # Fonction sigmoïde\n",
    "\n",
    "    # la fonction d'entropie binaire croisée\n",
    "    bce_fun = -np.mean(y * np.log(y_pred + 1e-10) + (1 - y) * np.log(1 - y_pred + 1e-10)) # 1e-10 Pour éviter log(0)\n",
    "    bce_grad = np.dot(X.T, (y_pred - y)) / m # gradient\n",
    "    \n",
    "    return bce_fun, bce_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36230089-a281-4bbd-8db8-2147237d8b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimisation(w_init, eta, X, y):\n",
    "    w = w_init\n",
    "    max_iter = 1000\n",
    "    for _ in range(max_iter):\n",
    "        bce_fun, bce_grad = binary_cross_entropy(X, y, w)\n",
    "        w -= eta * bce_grad  # Mise à jour des poids\n",
    "        \n",
    "    def taux_classification(X, y, w):\n",
    "        z = np.dot(X, w)  \n",
    "        y_pred = 1 / (1 + np.exp(-z))\n",
    "        y_pred = (y_pred >= 0.5).astype(int)\n",
    "        return np.mean(y_pred == y) * 100\n",
    "    \n",
    "    taux_train = taux_classification(X_train, y_train, w)\n",
    "    taux_test = taux_classification(X_test, y_test, w)\n",
    "    \n",
    "    return w, taux_train, taux_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acda8637-2a56-4982-9923-61b5a6565d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de classification sur l'ensemble d'entraînement : 99.85716433619005\n",
      "Taux de classification sur l'ensemble de test : 99.93234100135318\n"
     ]
    }
   ],
   "source": [
    "w_init = np.zeros(X_train.shape[1])  # Initialisation des poids à zéro\n",
    "eta = 0.1  # Taux d'apprentissage\n",
    "\n",
    "w_opt, taux_train, taux_test = optimisation(w_init, eta, X_train, y_train)\n",
    "print(\"Taux de classification sur l'ensemble d'entraînement :\", taux_train)\n",
    "print(\"Taux de classification sur l'ensemble de test :\", taux_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcfbc7-21f4-41f8-839b-a55ab7b50899",
   "metadata": {},
   "source": [
    "## Question 2 : Un petit réseau convolutif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "856f3b4e-6621-430f-a384-69e9856deeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Charger les données MNIST\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7a54b6a-49a9-493a-9b0a-2d9576269aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer uniquement les images des classes 0 et 1\n",
    "indices = (y == 0) | (y == 1)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Normaliser les données\n",
    "X = X / 255.0\n",
    "\n",
    "# Reshaper les données en format image pour CNN\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Encoder les étiquettes en one-hot (pour 2 classes)\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement (90%) et de test (10%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "afe3f7e9-2371-49fe-a335-ca81b5284d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construire le modèle CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Ajouter des couches convolutionnelles et de pooling\n",
    "# premier couche\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 2ème couche\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Aplatier les sorties des couches précédentes \n",
    "model.add(Flatten())\n",
    "\n",
    "# Ajouter une couche dense entièrement connectée\n",
    "model.add(Dense(128, activation='relu'))  # Couche cachée avec 128 neurones\n",
    "model.add(Dense(2, activation='softmax'))  # Couche de sortie (2 classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a6e0838-7b8b-4d6e-8496-481b7d1920ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.9858 - loss: 0.0438 - val_accuracy: 0.9986 - val_loss: 0.0067\n",
      "Epoch 2/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 1.1449e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.9986 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0043\n",
      "Epoch 5/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 4.2151e-04 - val_accuracy: 0.9993 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.6127e-05 - val_accuracy: 0.9993 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.3679e-06 - val_accuracy: 0.9993 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.0085e-05 - val_accuracy: 0.9993 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.0135e-06 - val_accuracy: 0.9993 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.3536e-06 - val_accuracy: 0.9993 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',             \n",
    "              loss='categorical_crossentropy',  \n",
    "              metrics=['accuracy'])          \n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=10,              \n",
    "                    batch_size=32,         \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    verbose=1)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0abfa553-83c7-4a8c-80e2-c3fb9f50c27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de classification sur l'ensemble de test : 99.93%\n"
     ]
    }
   ],
   "source": [
    "# Évaluation des performances\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Taux de classification sur l'ensemble de test : {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef670d4-f630-4691-b381-693cf0c0d57b",
   "metadata": {},
   "source": [
    "## Question 3 : Astuce du Noyau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e56aa14c-a764-48a2-afa5-1d224a939797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def G(x, y, sigma):\n",
    "    # Norme au carré entre x et y\n",
    "    distance = np.linalg.norm(x - y)**2\n",
    "    # Calcul du noyau gaussien\n",
    "    gaussian_kernel = np.exp(-distance / (2 * sigma**2))\n",
    "    \n",
    "    return gaussian_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42ad2a04-950f-4f53-b16a-446113ca7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3678794411714422\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2])\n",
    "y = np.array([2, 3])\n",
    "sigma = 1.0\n",
    "print(G(x, y, sigma))  # Renvoie une valeur entre 0 et 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d43b871c-9b45-45c8-a12e-2fae0185d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X_train, y_train, X_test, y_test, sigma, epochs=100, learning_rate=0.01):\n",
    "    N = X_train.shape[0]  \n",
    "    lbda = np.zeros(N)  # Initialisation des coefficients lambda à 0\n",
    "    \n",
    "    rate_training = []  # Les taux de classification sur l'entraînement\n",
    "    rate_test = []      # Les taux de classification sur le test\n",
    "\n",
    "    # Matrice du noyau gaussien\n",
    "    K_train = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K_train[i, j] = G(X_train[i], X_train[j], sigma)\n",
    "    \n",
    "    # Descente de gradient\n",
    "    for epoch in range(epochs):\n",
    "        # Prédictions sur l'ensemble d'entraînement\n",
    "        y_pred_train = np.dot(K_train, lbda)\n",
    "        \n",
    "        # Erreur entre prédictions et labels réels\n",
    "        error = y_pred_train - y_train\n",
    "        grad = 2 * np.dot(K_train, error)\n",
    "        \n",
    "        # Mise à jour des coefficients lambda\n",
    "        lbda -= learning_rate * grad\n",
    "        \n",
    "        # Calcul du taux de classification (entraînement)\n",
    "        y_pred_train_binary = np.sign(y_pred_train)  # Convertir en prédictions binaires\n",
    "        accuracy_train = np.mean(y_pred_train_binary == y_train) * 100\n",
    "        rate_training.append(accuracy_train)\n",
    "        \n",
    "        # Calcul du taux de classification (test)\n",
    "        y_pred_test = np.array([\n",
    "            np.sum(lbda * np.array([G(X_train[j], X_test[i], sigma) for j in range(N)]))\n",
    "            for i in range(X_test.shape[0])\n",
    "        ])\n",
    "        y_pred_test_binary = np.sign(y_pred_test)  # Convertir en prédictions binaires\n",
    "        accuracy_test = np.mean(y_pred_test_binary == y_test) * 100\n",
    "        rate_test.append(accuracy_test)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Taux de classification (entraînement) = {accuracy_train:.2f}% | Test = {accuracy_test:.2f}%\")\n",
    "\n",
    "    return lbda, rate_training, rate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9290b44c-6cdc-4221-bb67-aad46317f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "y = y.astype(int) \n",
    "\n",
    "indices = (y == 0) | (y == 1)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "X = X / 255.0\n",
    "\n",
    "# 0 devient -1, 1 reste 1\n",
    "y = np.where(y == 0, -1, 1)\n",
    "\n",
    "# Sous-échantillonner : 50 images de 0 et 50 images de 1\n",
    "X0, y0 = X[y == -1][:50], y[y == -1][:50]\n",
    "X1, y1 = X[y == 1][:50], y[y == 1][:50]\n",
    "X_subset = np.vstack([X0, X1])\n",
    "y_subset = np.hstack([y0, y1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db7f87fa-61ea-409c-b4d1-4c1983e87394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Taux de classification (entraînement) = 0.00% | Test = 100.00%\n",
      "Epoch 10: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 20: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 30: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 40: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 50: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 60: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 70: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 80: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Epoch 90: Taux de classification (entraînement) = 100.00% | Test = 100.00%\n",
      "Lambda optimisé : [-0.86738044 -0.86738044  0.83413468 -0.86738044  0.81153547 -0.86738044\n",
      "  0.86475017  0.79524098 -0.86725827 -0.86716832  0.86738044  0.86319402\n",
      " -0.86738044 -0.86738044  0.85767421 -0.86738043 -0.86716774  0.85954764\n",
      " -0.86738044  0.86121932 -0.86738044 -0.86738044  0.85846715 -0.86738044\n",
      "  0.82678071 -0.86738044  0.86616108  0.86267095 -0.86738036 -0.86737975\n",
      " -0.86738044 -0.86737975 -0.86738044  0.83394743 -0.86738044 -0.8672578\n",
      "  0.86738044 -0.86738044  0.86069219 -0.86738044 -0.86738044 -0.86738042\n",
      " -0.86738044 -0.86737973 -0.86737991  0.8617215  -0.86738044  0.86310087\n",
      " -0.86738039  0.86017798  0.83520842  0.86736125  0.71786814 -0.86738044\n",
      "  0.73320919  0.81348557 -0.86738044  0.85893879  0.8657984   0.84227242\n",
      "  0.86117412 -0.86737985  0.86708472 -0.86738044  0.86736409  0.85821968\n",
      "  0.86092807 -0.86738044  0.85592768  0.86738043  0.86607722  0.86132952\n",
      " -0.86738044 -0.86738044 -0.86737977  0.86536588 -0.86738044 -0.86738043\n",
      " -0.86738044  0.85078182  0.74702032  0.86619089  0.85941782  0.86147287\n",
      " -0.86738039  0.83968012  0.86738044 -0.86738044  0.74637767  0.86651312]\n",
      "Taux de classification final (entraînement) : 100.0\n",
      "Taux de classification final (test) : 100.0\n"
     ]
    }
   ],
   "source": [
    "sigma = 1.0 \n",
    "epochs = 100 \n",
    "learning_rate = 0.01  \n",
    "\n",
    "\n",
    "lbda, rate_training, rate_test = optimize(X_train, y_train, X_test, y_test, sigma, epochs, learning_rate)\n",
    "\n",
    "print(\"Lambda optimisé :\", lbda)\n",
    "print(\"Taux de classification final (entraînement) :\", rate_training[-1])\n",
    "print(\"Taux de classification final (test) :\", rate_test[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
