# -*- coding: utf-8 -*-
"""TD_IA_RL-RP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1elWxs1FjM77T8PRxfkDQEjum2EPPr3aB
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Tâche 1 :
###### Exploitez la base de données "possum.csv". Préparez cette base de données de manière à ce qu’elle soit correctement nettoyée.
###### Puis affichez les données des descripteurs ciblés

# Charger la base de données
df = pd.read_csv('possum.csv')

# Afficher les premières lignes du DataFrame pour vérifier son contenu
print(df.head())

# Vérification des informations sur les colonnes
print(df.shape)

sub_df=df[['footlgth','earconch']]
print(sub_df.describe())
print(sub_df.isnull().sum())
data_cleaned=sub_df.dropna()
print(sub_df.isnull().sum())
data_cleaned=sub_df.dropna()
# Visualisation de la relation entre footlength et earconch avec un scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(x='footlgth',y='earconch', data= data_cleaned)
plt.xlabel('Footlength')
plt.ylabel('Earconch')
plt.title('Relation entre Footlength et Earconch')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""#Tâche 1 :
###### Exploitez la base de données "possum.csv". Préparez cette base de données de manière à ce qu’elle soit correctement nettoyée.
###### Puis affichez les données des descripteurs ciblés
"""

# Charger la base de données
df = pd.read_csv('possum.csv')

# Afficher les premières lignes du DataFrame pour vérifier son contenu
print(df.head())

# Vérification des informations sur les colonnes
print(df.info())

# Affichage des descripteurs ciblés : footlength et earconch
df_descriptors = df[['footlgth', 'earconch']]
print(df_descriptors.head())

# Vérification des valeurs manquantes
print(df_descriptors.isnull().sum())

# Suppression des lignes avec des valeurs manquantes
df_clean = df_descriptors.dropna()

# Vérification
print(df_clean.isnull().sum())

print(df_clean.head())
print(df_clean.dtypes)

# Visualisation de la relation entre footlength et earconch avec un scatter plot
footlgth = df_clean['footlgth']
earconch = df_clean['earconch']
plt.scatter(footlgth, earconch)
plt.title('Relation entre footlgth et earconch')
plt.xlabel('Longueur d''empreinte')
plt.ylabel('Taille pavillon de l''oreille')
plt.show()

def predict_model(alpha, beta, X):
    return alpha * X + beta

def mean_square_error0(y_reel, y_pred):
    mse = ((y_reel - y_pred) ** 2).mean()
    return mse

# Exemples de paramètres
alphas_betas = [(0.25, 0.5), (0.75, 1), (1, 2)]

# Calcul des MSE pour chaque modèle
for alpha, beta in alphas_betas:
    predictions = predict_model(alpha, beta, footlgth)
    error = mean_square_error0(earconch, predictions)
    print(f"Model (alpha={alpha}, beta={beta}): MSE = {error:.3f}")

# Exemples de paramètres
alphas_betas = [(0.25, 0.5), (0.75, 1), (1, 2)]

# Créer le plot
plt.figure()
plt.scatter(footlgth, earconch, label='Données observées')  # Points observés

# Initialisation d'une liste pour stocker les MSE
mse_values = []

# Tracer chaque modèle et calculer les MSE
for alpha, beta in alphas_betas:
    predictions = predict_model(alpha, beta, footlgth)
    error = mean_square_error0(earconch, predictions)
    mse_values.append((alpha, beta, error))  # Stocker les résultats
    plt.plot(footlgth, predictions, label=f'Modèle (alpha={alpha}, beta={beta})')

# Ajouter des annotations
plt.xlabel('Longueur d\'empreinte (footlgth)')
plt.ylabel('Taille du pavillon de l\'oreille (earconch)')
plt.title('Comparaison des modèles de régression linéaire')
plt.legend()
plt.show()

# Afficher les MSE pour chaque modèle
print("MSE pour chaque modèle :")
for alpha, beta, error in mse_values:
    print(f"Model (alpha={alpha}, beta={beta}): MSE = {error:.3f}")

# Solution 1
# Calcul des paramètres optimaux alpha et beta
def optimal_coefficients(x, y):
    x_bar = x.mean()
    y_bar = y.mean()

    # Calcul de alpha
    numerateur = ((x - x_bar) * (y - y_bar)).sum()
    denominateur = ((x - x_bar) ** 2).sum()
    alpha = numerateur / denominateur

    # Calcul de beta
    beta = y_bar - alpha * x_bar

    return alpha, beta

# Calcul des coefficients optimaux
alpha_opt, beta_opt = optimal_coefficients(footlgth, earconch)
print(f"Coefficients optimaux : alpha = {alpha_opt:.3f}, beta = {beta_opt:.3f}")

# Prédiction avec les paramètres optimaux
optimal_predictions = predict_model(alpha_opt, beta_opt, footlgth)

# Calcul de la MSE pour les paramètres optimaux
optimal_mse = mean_square_error0(earconch, optimal_predictions)
print(f"Erreur quadratique moyenne (MSE) avec les paramètres optimaux : {optimal_mse:.3f}")

# Visualisation du modèle optimal
plt.figure(figsize=(10, 6))
plt.scatter(footlgth, earconch, color='blue', label='Données observées')  # Points observés
plt.plot(footlgth, optimal_predictions, color='green', label=f'Modèle optimal (MSE={optimal_mse:.3f})')
plt.xlabel('Longueur d\'empreinte (footlgth)')
plt.ylabel('Taille du pavillon de l\'oreille (earconch)')
plt.title('Modèle de régression linéaire optimal')
plt.legend()
plt.show()

# Solution 2
# Calcul des coefficients alpha et beta

x = footlgth
y = earconch
x_bar = x.mean()
y_bar = y.mean()

# Calcul de alpha
numerator = ((x - x_bar) * (y - y_bar)).sum()
denominator = ((x - x_bar) ** 2).sum()
alpha_optimal = numerator / denominator

# Calcul de beta
beta_optimal = y_bar - alpha_optimal * x_bar

# Affichage des coefficients
print(f"Coefficients optimaux : alpha = {alpha_optimal:.3f}, beta = {beta_optimal:.3f}")

# Prédiction avec les paramètres optimaux
optimal_y_predictions = predict_model(alpha_optimal, beta_optimal, x)

# Calcul de la MSE pour les paramètres optimaux
optimal_mse = mean_square_error0(y, optimal_y_predictions)
print(f"Erreur quadratique moyenne (MSE) avec les paramètres optimaux : {optimal_mse:.3f}")

# Visualisation du modèle optimal
plt.figure()
plt.scatter(x, y)
plt.plot(x, optimal_y_predictions, color='orange', label=f'Modèle optimal (MSE={optimal_mse:.3f})')
plt.xlabel('Longueur d\'empreinte (footlgth)')
plt.ylabel('Taille du pavillon de l\'oreille (earconch)')
plt.title('Modèle de régression linéaire optimal')
plt.legend()
plt.show()

"""metrique de regression :

-mse
-mae
-r2

### Tache 6 : En utilisant la documentation de la librairie, utilisez les fonctions fit pour l’apprentissage et predict pour prédire les réponses du modèle sur les données.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# X les données d'entrée avec un descripteur
# Préparation des données
X = footlgth.values.reshape(-1, 1)  # Reshape pour scikit-learn (matrice 2D)
y = earconch.values  # Les valeurs cibles

# Création du modèle de régression linéaire
model = LinearRegression()

# Entraînement du modèle
model.fit(X, y)

# Coefficients du modèle
alpha_sklearn = model.coef_[0]  # Coefficient directeur (pente)
beta_sklearn = model.intercept_  # Ordonnée à l'origine
print(f"Coefficients avec scikit-learn : alpha = {alpha_sklearn:.3f}, beta = {beta_sklearn:.3f}")

# Prédictions sur les données d'entraînement
y_pred = model.predict(X)

# Calcul de la MSE avec scikit-learn
mse_sklearn = mean_squared_error(y, y_pred)
print(f"Erreur quadratique moyenne (MSE) avec scikit-learn : {mse_sklearn:.3f}")

# Visualisation de la droite de régression obtenue
plt.figure(figsize=(10, 6))
plt.scatter(footlgth, earconch, color='blue', label='Données observées')  # Points observés
plt.plot(footlgth, y_pred, color='red', label=f'Droite de régression (MSE={mse_sklearn:.3f})')
plt.xlabel('Longueur d\'empreinte (footlgth)')
plt.ylabel('Taille du pavillon de l\'oreille (earconch)')
plt.title('Modèle de régression linéaire avec scikit-learn')
plt.legend()
plt.show()

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Préparation des données
X_train = footlgth.values  # Extraire les valeurs de la colonne footlgth comme données d'entrée
X_train_reshaped = np.array(X_train).reshape(-1, 1)  # Reshape en matrice 2D pour être compatible avec scikit-learn
y_train = earconch.values  # Extraire les valeurs de la colonne earconch comme données cibles

# Création du modèle de régression linéaire
model = LinearRegression()

# Entraînement du modèle sur les données d'entrée et les cibles
model.fit(X_train_reshaped, y_train)

# Coefficients du modèle
alpha_sklearn = model.coef_[0]  # Coefficient directeur (pente de la droite)
beta_sklearn = model.intercept_  # Ordonnée à l'origine (point d'intersection avec l'axe des y)
print(f"Coefficients avec scikit-learn : alpha = {alpha_sklearn:.3f}, beta = {beta_sklearn:.3f}")

# Prédictions sur les données d'entraînement
y_pred = model.predict(X_train_reshaped)

# Calcul de la MSE avec scikit-learn
mse_sklearn = mean_squared_error(y_train, y_pred)
print(f"Erreur quadratique moyenne (MSE) avec scikit-learn : {mse_sklearn:.3f}")

# Visualisation de la droite de régression obtenue
plt.figure(figsize=(10, 6))  # Taille du graphique
plt.scatter(footlgth, earconch, label='Données observées')  # Points réels observés
plt.plot(footlgth, y_pred, color='orange', label=f'Droite de régression (MSE={mse_sklearn:.3f})')  # Droite du modèle
plt.xlabel('Longueur d\'empreinte (footlgth)')  # Nom de l'axe x
plt.ylabel('Taille du pavillon de l\'oreille (earconch)')  # Nom de l'axe y
plt.title('Modèle de régression linéaire avec scikit-learn')  # Titre du graphique
plt.legend()  # Affiche la légende
plt.show()  # Affiche le graphique

"""#### Tache 7"""

# Définir la fonction f(x)
def compute_fx(x):
    """
    Calcule la valeur de la fonction f(x) = (12 * sin(x)) / (x + eps) pour un vecteur d'entrée x.
    """
    epsilon = np.finfo(np.float32).eps  # Petite valeur pour éviter la division par zéro
    res = (12 * np.sin(x)) / (x + epsilon)
    return res

# Générer 40 points dans l'intervalle [-3, 10]
x_values = np.linspace(-3, 10, 40)

# Calculer f(x) pour ces points
f_values = compute_fx(x_values)

# Ajouter un bruit aléatoire de moyenne 0 et d'écart-type 1
noise = np.random.normal(loc=0, scale=1, size=x_values.shape)
f_values_noisy = f_values + noise

# Visualisation de la fonction avec bruit
plt.figure(figsize=(10, 6))
plt.scatter(x_values, f_values_noisy, alpha=0.8)
plt.title('Graphique de f(x) avec bruit')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.grid()
plt.show()

"""### 2.2 Séparation des données"""

from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

# Générer des données factices
def compute_fx(x):
    epsilon = np.finfo(np.float32).eps  # Évite la division par zéro
    return 12 * np.sin(x) / (x + epsilon)

# Génération de données
x_values = np.linspace(-3, 10, 40)
f_values = compute_fx(x_values)
noise = np.random.normal(loc=0, scale=1, size=len(x_values))
f_values_noisy = f_values + noise

# Préparer les données pour scikit-learn
X_data = x_values.reshape(-1, 1)  # Reshape pour une matrice 2D
y_data = f_values_noisy

# Séparation des données (1/3 pour la validation)
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33, random_state=12)

# Afficher les dimensions des ensembles
print(f"Taille de l'ensemble d'entraînement : {len(X_train)} points")
print(f"Taille de l'ensemble de test : {len(X_test)} points")

# Visualisation de la séparation
plt.figure(figsize=(10, 6))
plt.scatter(X_train, y_train, color='blue', label='Données d\'entraînement')
plt.scatter(X_test, y_test, color='red', label='Données de test')
plt.title('Séparation des données : Entraînement vs Test', fontsize=14, fontweight='bold')
plt.xlabel('x', fontsize=12)
plt.ylabel('f(x) (avec bruit)', fontsize=12)
plt.legend(fontsize=10)
plt.grid(alpha=0.3)
plt.show()

"""### 2.3 Modèle de régression polynomiale
#### Tache 2 :
"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline

# Création du modèle polynomial avec Ridge Regression
degree = 5  # Degré du polynôme
model = make_pipeline(
    PolynomialFeatures(degree=degree),  # Transformation polynomiale des données
    Ridge(alpha=1.0)  # Modèle de Ridge Regression (alpha = paramètre de régularisation)
)

# Entraînement du modèle
model.fit(X_train, y_train)

# Prédictions
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Évaluation des performances
mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)

print(f"Erreur quadratique moyenne sur les données d'entraînement : {mse_train:.3f}")
print(f"Erreur quadratique moyenne sur les données de test : {mse_test:.3f}")

# Visualisation
plt.figure(figsize=(10, 6))
plt.scatter(X_train, y_train, color='blue', label='Données d\'entraînement')
plt.scatter(X_test, y_test, color='red', label='Données de test')
x_curve = np.linspace(-3, 10, 200).reshape(-1, 1)  # Plus de points pour une courbe lisse
y_curve = model.predict(x_curve)
plt.plot(x_curve, y_curve, color='green', label=f'Modèle polynomial (degré={degree})')
plt.title('Régression polynomiale avec Ridge')
plt.xlabel('x')
plt.ylabel('f(x) (avec bruit)')
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# Liste des degrés à tester
degrees = [1, 2, 3, 6, 9, 12]
colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown']

# Préparer un espace pour visualiser les courbes
plt.figure(figsize=(12, 8))

# Itérer sur chaque degré de polynôme
for idx, degree in enumerate(degrees):
    # Créer un modèle polynomial avec Ridge
    model = make_pipeline(
        PolynomialFeatures(degree=degree),
        Ridge(alpha=1.0)
    )

    # Entraîner le modèle
    model.fit(X_train, y_train)

    # Calculer les prédictions pour l'affichage
    x_curve = np.linspace(-3, 10, 100).reshape(-1, 1)  # Plus de points pour une courbe lisse
    y_curve = model.predict(x_curve)

    # Calculer les erreurs
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    mse_train = mean_squared_error(y_train, y_train_pred)
    mse_test = mean_squared_error(y_test, y_test_pred)

    # Afficher la courbe pour ce degré
    plt.plot(x_curve, y_curve, label=f'Degré={degree}', color=colors[idx])

# Afficher les données d'entraînement et de test
plt.scatter(X_train, y_train, color='black', marker='o', label='Données d\'entraînement', alpha=0.7)
plt.scatter(X_test, y_test, color='red', marker='x', label='Données de test', alpha=0.7)

# Ajouter des annotations au graphique
plt.title('Modèles de régression polynomiale pour différents degrés', fontsize=14)
plt.xlabel('x', fontsize=12)
plt.ylabel('f(x) (avec bruit)', fontsize=12)
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# Fonction pour calculer RSS (Residual Sum of Squares)
def residual_sum_of_squares(y_true, y_pred):
    return ((y_true - y_pred) ** 2).sum()

# Liste des degrés à tester
degrees = [1, 2, 3, 6, 9, 12]

# Stocker les erreurs RSS pour chaque degré
rss_results = {}

for degree in degrees:
    # Créer le modèle polynomial
    model = make_pipeline(
        PolynomialFeatures(degree=degree),
        Ridge(alpha=1.0)
    )

    # Entraîner le modèle sur les données d'entraînement
    model.fit(X_train, y_train)

    # Prédire les valeurs sur les données d'entraînement
    y_train_pred = model.predict(X_train)

    # Calculer l'erreur RSS
    rss = residual_sum_of_squares(y_train, y_train_pred)
    rss_results[degree] = rss

# Afficher les résultats
print("Erreurs RSS pour les différents degrés :")
for degree, rss in rss_results.items():
    print(f"Degré={degree}: RSS={rss:.2f}")

from sklearn.metrics import mean_squared_error

# Calcul de RSS sur les données de test
def calculate_rss(y_true, y_pred):
    """Calcule la somme des erreurs résiduelles au carré (RSS)."""
    return ((y_true - y_pred) ** 2).sum()

# Définir les degrés de polynôme à évaluer
degrees = [1, 2, 3, 6, 9, 12]

# Initialisation des résultats pour afficher les RSS
test_rss_results = {}

# Générer des prédictions et calculer le RSS pour chaque degré
for degree in degrees:
    # Création du pipeline avec PolynomialFeatures et Ridge
    model = make_pipeline(PolynomialFeatures(degree), Ridge())
    model.fit(X_train, y_train)  # Entraîner sur les données d'apprentissage

    # Prédictions sur les données de test
    y_test_pred = model.predict(X_test)

    # Calcul du RSS sur les données de test
    test_rss = calculate_rss(y_test, y_test_pred)
    test_rss_results[degree] = test_rss

    print(f"Degree {degree}: RSS on test data = {test_rss:.2f}")

# Visualisation des erreurs RSS sur les données de test
plt.figure(figsize=(10, 6))
plt.plot(test_rss_results.keys(), test_rss_results.values(), marker='o', label='RSS on Test Data')
plt.xlabel('Degree of Polynomial')
plt.ylabel('Residual Sum of Squares (RSS)')
plt.title('Validation des modèles : Erreur RSS en fonction du degré du polynôme')
plt.grid(True)
plt.legend()
plt.show()